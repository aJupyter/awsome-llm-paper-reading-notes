# 一、RAG
[20240109组会分享——RAG_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1V5411i7M7/?spm_id_from=333.337.search-card.all.click&vd_source=67ad56424e3b1535354079cd8d9ddb15)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042099873-fc8a1171-524f-4557-bdf4-f4c548350593.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042114435-86865253-2048-4096-9f69-0adabb6d310f.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042129136-b99f327b-c214-40e8-8be8-bc8ee779b0fb.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042143963-bd9f7cbc-add8-4230-8651-2cd149395769.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042162773-286e93a9-25bf-4e1b-862a-cd5d225d1745.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042174370-22531b0e-f17b-4d69-bb77-5e4ab79149a7.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042198465-4f9cf5bd-b9bc-4c6e-9330-201509fbed9c.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042230728-ff1244a5-bf6e-4cb6-b5e7-09608d6e6f5d.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042259207-e27fae91-638e-4466-87c5-d4b78ce64d92.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042304152-c70733b8-8e0c-4c9a-ab4c-492316284fb3.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042318488-c41e8746-dc31-47be-819b-22d91c2fd52e.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042336612-a7cbb158-8c73-4527-9909-75f13d660011.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042391865-e55ab4b2-350a-497e-bf83-e6fcd3f8c503.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042427517-23a80f95-c1da-49d4-8f58-23b2eeb68afd.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042441574-bc40cf17-9310-445e-b521-50d755bcd36d.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042451467-29bfa009-37e1-412e-b396-7537a47d5a99.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042462389-51253b82-a4aa-4bd8-bff8-48f31acbc3fe.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042471194-0970707f-2679-4c4e-8d01-6bc6eea3be20.png)

---

# 二、CRAG: 高级 RAG 新范式！
[CRAG: 高级 RAG 新范式！（2024.2.16，@Qiyuan）_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1yK42187tv/?spm_id_from=333.337.search-card.all.click&vd_source=67ad56424e3b1535354079cd8d9ddb15)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042850941-b8665369-ca18-4b92-9b25-0aae117ce01d.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042891092-e8891b70-6255-4a38-9f4d-cf575c108df6.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042912191-442fada8-dde9-4892-88b3-9022b9a712c6.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042932473-540d50b6-2e37-44ac-890a-76f8a158aaf1.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042977660-da998636-fc0a-4f9b-92b6-bdf0be229c65.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709042997777-073794c8-8ad8-4350-90ba-426e10910dac.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709043009906-fd6f6bc4-f253-4875-a5b9-56dd336a6623.png)

+ 检索的时候仅关注语义，并不清楚内容是否与问题相关

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709043210051-203dc9de-292c-43af-aa06-edb47a4ea860.png)

+ correct 的文档，切分成更小的 chunk， 继续用评估器评估只保留 correct 的片段
+ incorrect 的文档，重写问题后上网搜
+ 模棱两可的文档同时用上面这两种方法处理，然后将内容合并

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709043621027-70ebf3d3-8d7b-4998-9ad8-1df1c654dff5.png)

检索器？

+ 向量数据库，稠密检索
+ 稀疏检索（TF-IDF）
+ 重排

检索评估也可以用大模型（prompt）  


其他资源：

self-RAG、RAGs

贾清杨项目

多模态 RAG



评估的东西：

+ 问题
+ 检索的文档
+ 答案

---

# 三、RAGs
[https://github.com/rexrex9/basic_neural_networks_pytorch/blob/main/chapter_llm/openai_conn/conn.py](https://github.com/rexrex9/basic_neural_networks_pytorch/blob/main/chapter_llm/openai_conn/conn.py)

[骰子AI的个人空间-骰子AI个人主页-哔哩哔哩视频](https://space.bilibili.com/497998686)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709088200283-7be76d93-b2a1-4830-9d1c-e9582ea07a88.png)

## 1.答案相似度
![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709088327932-f3237005-69f4-4ba6-b958-3aaebe6665f8.png)

+ 坑，不设置为 None 的话会是一个 01 分布，设置为 None 可以返回具体的数值

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709088375691-e8baebf7-7260-4a6d-bb30-ca251fb7f616.png)

---

## 2.答案相关度
![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709088499895-4f2dcf8d-23c2-4a27-a409-f3eca5ee9313.png)

---

## 3.语境精确率
![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709088582406-73eec352-0fc1-473a-9147-63f29453e7ea.png)

---

## 4.语境相关性
![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709088617972-2df86c6d-1b1b-4869-bf96-41414924f6da.png)

---

## 5.语境召回率
![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709088723589-cd1d577e-417e-49fc-9724-aa36f2f6c836.png)

+ 坑

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709088866444-7fc1c4f3-d1e7-4357-96dc-cb6c3829db35.png)

---

## 6.忠实性
![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709088938755-3dd886c6-d66c-4714-8327-73ce6e6cf1eb.png)

---

## 7.答案正确性
![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709089093826-78fa258d-3aa3-46f8-a02d-e750bb467ad8.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709089261577-9585eed1-b28a-4f1e-af83-63a2ef8fb96e.png)

+ 坑

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709089573903-d58dfe8e-12da-4564-912a-6b404d5f6b41.png)

---

## 8.层面评判
![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709089300861-f7fbad3e-6a40-4928-bf95-eabfbcd66608.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709089360556-2d0bfe36-cc85-4b9a-a7eb-3f1774be2f72.png)

+ 自定义一个

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709089467598-8e267f01-7cb4-4efc-9421-585f167c1abe.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709089511208-38494b20-4bd7-4902-81ca-632305fbcf05.png)

---

## 总结
![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709089542084-c5e863ac-7b4f-420c-b8cf-d655bdb9ac58.png)

---

# 四、Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks NIPS2020（鼻祖）
[RAG和Self-RAG简介_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1YC4y1U7u5/?spm_id_from=333.337.search-card.all.click&vd_source=67ad56424e3b1535354079cd8d9ddb15)

[Notion – The all-in-one workspace for your notes, tasks, wikis, and databases.](https://nobleai.notion.site/LLM-RAG-acca19ee9a884fbc952e712dccd61832)

## 摘要
 该论文介绍了一种检索增强生成（Retrieval-Augmented Generation, RAG）模型，该模型结合了预训练的参数记忆和非参数记忆用于语言生成。参数记忆是一个预训练的序列到序列模型，非参数记忆是一个密集的维基百科向量索引，通过预训练的神经检索器访问。**论文探讨了两种RAG的形式：一种是在整个生成序列中条件相同的检索段落，另一种可以在每个令牌上使用不同的段落。**模型在一系列知识密集型NLP任务上进行了微调和评估，在三个开放域问答任务上设定了新的最先进结果。RAG模型被证明可以生成比仅参数序列到序列模型更具体、多样和事实性的语言。  

## Introduction
Pre-trained neural language models:

+ learn a substantial amount of in-depth knowledge from data without any access to an external memory.
+ a parameterized implicit knowledge base
+ they cannot easily expand or revise their memory.
+ can’t straightforwardly provide insight into their predictions.
+ may produce “hallucinations”.

> Hybrid models that combine parametric memory with non-parametric (i.e., retrieval-based) memories can address some of these issues because knowledge can be directly revised and expanded, and accessed knowledge can be inspected and interpreted.
>

+ REALM and ORQA = masked language model + differentiable retriever, but only explored open-domain extractive question answering.

## RAG
+ **pre-trained, parametric-memory generation models** **+** **a non-parametric memory**
+ a general-purpose fine-tuning approach (RAG)
+ pre-trained model ⇒ pre-trained seq2seq transformer
+ non-parametric memory ⇒ dense vector index of Wikipedia
+ retriever ⇒ pre-trained neural retriever
+ **finetune:** all 3 combined, end-to-end

**Benchmarks**:

+ Natural Questions, WebQuestions and CuratedTrec
+ TriviaQA
+ MS-MARCO, Jeopardy question generation
+ FEVER fact verification

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709102125356-910e8f09-1059-4649-9849-129a2a4045d1.png)

## Methods
+ **user prompt: **![image](https://www.yuque.com/api/services/graph/generate_redirect/latex?x)
+ **database index**: ![image](https://www.yuque.com/api/services/graph/generate_redirect/latex?z)
+ **Retriever**: ![image](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7B%5Ceta%7D(z%7Cx))
+ **generator**: ![image](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7B%5Ctheta%7D(y_i%7Cx%2Cz%2Cy_%7B1%3Ai-1%7D))

### RAG-Sequence Model


![image](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Bseq%7D%5Capprox%5Csum_%7Bz%5Cin%20top-K(%5Ccdot%7Cx)%7Dp_%7B%5Ceta%7D(z%7Cx)p_%7B%5Ctheta%7D(y%7Cx%2Cz)%3D%5Csum_%7Bz%5Cin%20top-K(%5Ccdot%7Cx)%7Dp_%7B%5Ceta%7D(z%7Cx)%5Cprod%20_i%5ENp_%7B%5Ctheta%7D(y_%7Bi%7D%7Cx%2Cz%2Cy_%7B1%3Ai-1%7D)%0A)



### RAG-Token Model


![image](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7Btok%7D%5Capprox%5Cprod%20_i%5EN%5Csum_%7Bz%5Cin%20top-K(%5Ccdot%7Cx)%7Dp_%7B%5Ceta%7D(z%7Cx)p_%7B%5Ctheta%7D(y_%7Bi%7D%7Cx%2Cz%2Cy_%7B1%3Ai-1%7D)%0A)



## Retriever: DPR
+ Bert based query encoder: ![image](https://www.yuque.com/api/services/graph/generate_redirect/latex?q(x))
+ Bert based document encoder: d(z)



![image](https://www.yuque.com/api/services/graph/generate_redirect/latex?p_%7B%5Ceta%7D(z%7Cx)%5Cpropto%20%5Cexp(d(z)%5E%5Ctop%20q(x))%20%0A)



## Generator: BART
BART-large: 400M parameters

## Documents
Wikipedia December 2018 dump

split into disjoint 100-words chunks

21M documents

# Performance
![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709102264882-a74d644f-5e82-4310-b181-8f931b97cb2a.png)

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709102268850-ed54db02-48f2-4831-9a31-b2827d23fa5d.png)

---

# 五、Self-RAG 2023
## 摘要
尽管大型语言模型（LLMs）具有显著的能力，但它们经常产生包含事实不准确信息的回应，这是因为它们完全依赖于它们封装的参数知识。检索增强生成（Retrieval-Augmented Generation，简称RAG）是一种特设方法，它通过检索相关知识来增强语言模型（LM），减少了此类问题。然而，不加选择地检索并整合固定数量的检索段落，不论检索是否必要或段落是否相关，都会降低LM的多功能性，或可能导致生成无用的回应。我们引入了一个名为自反思检索增强生成（Self-Reflective Retrieval-Augmented Generation，简称SELF-RAG）的新框架，通过检索和自我反思来提升LM的质量和事实性。我们的框架训练了一个可以按需适应性检索段落的任意单一语言模型，并使用称为反思标记的特殊令牌来生成和反思检索到的段落及其自身的生成内容。在推理阶段生成反思标记使得LM在控制性方面得到增强，使其能够根据不同任务需求调整自身行为。实验表明，SELF-RAG（具有70亿和130亿参数）在多种任务上显著优于最先进的LLMs和检索增强模型。特别是，在开放领域问答、推理和事实验证任务上，SELF-RAG优于ChatGPT和检索增强的Llama2-chat，并且在长篇生成的事实准确性和引用准确性方面相对于这些模型有显著提升。

## Intro
**RAG**:

+ may hinder the versatility（多样性） of LLMs
+ introduce unnecessary or off-topic passages that lead to low-quality generations
+ the output is not guaranteed to be consistent with retrieved relevant passages since the models are not explicitly trained to leverage and follow facts from provided passages.

## ![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709102337165-e4074e9a-f009-4e27-9ba9-882cd57e97bc.png)Self-RAG
+ learn to reflect on its own generation process given a task input by generating both task output and intermittent special tokens
+ Reflection tokens are categorized into _**retrieval**_ and _**critique**_ tokens to indicate the need for retrieval and its generation quality respectively



LLM 通过生成反思标记，来告诉我们它对检索到的文本和自己生成的文本满意不满意

找到最相关的文档（给检索的文档打分）然后进行生成

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709102391264-8a37de66-1034-4deb-a8f2-5b860a8b743c.png)

+ Retrieve 根据输入的问题 x 和生成的 y 是否要检索
+ IsRel 文档与问题是否相关
+ IsSup 生成的回答与检索的文档是否相关
+ IsUse 生成的回答与问题是否相关

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709102454469-80b78916-7838-49d5-bd82-5e85f80951bf.png)

---

## 问题
1. token 不在 llm 的语料库中=》用 gpt4 API 往语料中插入 token，让 LLM 去学怎么生成 token（数据量太大，不可行）=》用 gpt4 在一小部分的数据上生成 token，微调另外一个 LLM 去学习怎么生成 token，再用这个 LLM 去调整数据
2. 有了带 token 的数据，生成 LLM 怎么学：先让打 token 的模型判断一下语言片段后有没有 token
3. 速度慢：每生成一个答案都需要检索和生成，时间开销大

![](https://cdn.nlark.com/yuque/0/2024/png/12752365/1709096036489-f4ed3ad4-7f81-4714-bf0c-638047c61df3.png)

---

